{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "HWOxK9T5I8sb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Chatbot based on Seq2Seq Beam Search + Attention + Reinforcment Learning(Experimental)\n",
        "- Tensorflow 1.4.0+ is required.\n",
        "- This is based on [NMT Tutorial](https://github.com/tensorflow/nmt).\n",
        "- Experiment [notes](https://github.com/higepon/tensorflow_seq2seq_chatbot/wiki).\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "kK1r053SI2f9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5406
        },
        "outputId": "1cb3f0b3-68ad-4854-c2a9-e0a59e85ec6f"
      },
      "cell_type": "code",
      "source": [
        "# Special commands should be located here.\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "!apt-get -qq install -y mecab libmecab-dev mecab-ipadic mecab-ipadic-utf8\n",
        "\n",
        "!pip -q install git+https://github.com/mrahtz/easy-tf-log#egg=easy-tf-log[tf]\n",
        "!pip install pushbullet.py\n",
        "!pip install tweepy pyyaml\n",
        "!pip install mecab-python3\n",
        "\n",
        "def auth_google_drive():\n",
        "  # Generate creds for the Drive FUSE library.\n",
        "  if not os.path.exists('drive'):\n",
        "    from oauth2client.client import GoogleCredentials\n",
        "    creds = GoogleCredentials.get_application_default()\n",
        "    import getpass\n",
        "    !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "    vcode = getpass.getpass()\n",
        "    !echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}  \n",
        "\n",
        "def mount_google_drive():\n",
        "  if not os.path.exists('drive'):\n",
        "    os.makedirs('drive', exist_ok=True)\n",
        "    !google-drive-ocamlfuse drive \n",
        "    \n",
        "def kill_docker():\n",
        "  !kill -9 -1  \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package cron.\n",
            "(Reading database ... 18396 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cron_3.0pl1-128ubuntu5_amd64.deb ...\n",
            "Unpacking cron (3.0pl1-128ubuntu5) ...\n",
            "Selecting previously unselected package libapparmor1:amd64.\n",
            "Preparing to unpack .../01-libapparmor1_2.11.0-2ubuntu17.1_amd64.deb ...\n",
            "Unpacking libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Selecting previously unselected package libdbus-1-3:amd64.\n",
            "Preparing to unpack .../02-libdbus-1-3_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dbus.\n",
            "Preparing to unpack .../03-dbus_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking dbus (1.10.22-1ubuntu1) ...\n",
            "Preparing to unpack .../04-gnupg_2.1.15-1ubuntu8.1_amd64.deb ...\n",
            "Unpacking gnupg (2.1.15-1ubuntu8.1) over (2.1.15-1ubuntu8) ...\n",
            "Preparing to unpack .../05-gnupg-agent_2.1.15-1ubuntu8.1_amd64.deb ...\n",
            "Unpacking gnupg-agent (2.1.15-1ubuntu8.1) over (2.1.15-1ubuntu8) ...\n",
            "Selecting previously unselected package dirmngr.\n",
            "Preparing to unpack .../06-dirmngr_2.1.15-1ubuntu8.1_amd64.deb ...\n",
            "Unpacking dirmngr (2.1.15-1ubuntu8.1) ...\n",
            "Selecting previously unselected package distro-info-data.\n",
            "Preparing to unpack .../07-distro-info-data_0.36ubuntu0.2_all.deb ...\n",
            "Unpacking distro-info-data (0.36ubuntu0.2) ...\n",
            "Selecting previously unselected package libkmod2:amd64.\n",
            "Preparing to unpack .../08-libkmod2_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Selecting previously unselected package kmod.\n",
            "Preparing to unpack .../09-kmod_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking kmod (24-1ubuntu2) ...\n",
            "Selecting previously unselected package lsb-release.\n",
            "Preparing to unpack .../10-lsb-release_9.20160110ubuntu5_all.deb ...\n",
            "Unpacking lsb-release (9.20160110ubuntu5) ...\n",
            "Selecting previously unselected package libgirepository-1.0-1:amd64.\n",
            "Preparing to unpack .../11-libgirepository-1.0-1_1.54.1-1_amd64.deb ...\n",
            "Unpacking libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package gir1.2-glib-2.0:amd64.\n",
            "Preparing to unpack .../12-gir1.2-glib-2.0_1.54.1-1_amd64.deb ...\n",
            "Unpacking gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package iso-codes.\n",
            "Preparing to unpack .../13-iso-codes_3.75-1_all.deb ...\n",
            "Unpacking iso-codes (3.75-1) ...\n",
            "Selecting previously unselected package libdbus-glib-1-2:amd64.\n",
            "Preparing to unpack .../14-libdbus-glib-1-2_0.108-2_amd64.deb ...\n",
            "Unpacking libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Selecting previously unselected package python-apt-common.\n",
            "Preparing to unpack .../15-python-apt-common_1.4.0~beta3build2_all.deb ...\n",
            "Unpacking python-apt-common (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-apt.\n",
            "Preparing to unpack .../16-python3-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python3-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-dbus.\n",
            "Preparing to unpack .../17-python3-dbus_1.2.4-1build3_amd64.deb ...\n",
            "Unpacking python3-dbus (1.2.4-1build3) ...\n",
            "Selecting previously unselected package python3-gi.\n",
            "Preparing to unpack .../18-python3-gi_3.24.1-2build1_amd64.deb ...\n",
            "Unpacking python3-gi (3.24.1-2build1) ...\n",
            "Selecting previously unselected package module-init-tools.\n",
            "Preparing to unpack .../19-module-init-tools_24-1ubuntu2_all.deb ...\n",
            "Unpacking module-init-tools (24-1ubuntu2) ...\n",
            "Selecting previously unselected package python-apt.\n",
            "Preparing to unpack .../20-python-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python-pycurl.\n",
            "Preparing to unpack .../21-python-pycurl_7.43.0-2build2_amd64.deb ...\n",
            "Unpacking python-pycurl (7.43.0-2build2) ...\n",
            "Selecting previously unselected package python-software-properties.\n",
            "Preparing to unpack .../22-python-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package python3-software-properties.\n",
            "Preparing to unpack .../23-python3-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python3-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package software-properties-common.\n",
            "Preparing to unpack .../24-software-properties-common_0.96.24.17_all.deb ...\n",
            "Unpacking software-properties-common (0.96.24.17) ...\n",
            "Selecting previously unselected package unattended-upgrades.\n",
            "Preparing to unpack .../25-unattended-upgrades_0.98ubuntu1.1_all.deb ...\n",
            "Unpacking unattended-upgrades (0.98ubuntu1.1) ...\n",
            "Setting up python-apt-common (1.4.0~beta3build2) ...\n",
            "Setting up python3-apt (1.4.0~beta3build2) ...\n",
            "Setting up iso-codes (3.75-1) ...\n",
            "Setting up distro-info-data (0.36ubuntu0.2) ...\n",
            "Setting up python-pycurl (7.43.0-2build2) ...\n",
            "Setting up lsb-release (9.20160110ubuntu5) ...\n",
            "Setting up libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Setting up libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Setting up gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting up libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\r\n",
            "Setting up unattended-upgrades (0.98ubuntu1.1) ...\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/20auto-upgrades with new version\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/50unattended-upgrades with new version\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up gnupg-agent (2.1.15-1ubuntu8.1) ...\n",
            "Setting up dirmngr (2.1.15-1ubuntu8.1) ...\n",
            "Setting up cron (3.0pl1-128ubuntu5) ...\n",
            "Adding group `crontab' (GID 102) ...\n",
            "Done.\n",
            "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
            "update-rc.d: warning: stop runlevel arguments (1) do not match cron Default-Stop values (none)\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Setting up kmod (24-1ubuntu2) ...\n",
            "Setting up libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Setting up gnupg (2.1.15-1ubuntu8.1) ...\n",
            "Setting up python3-gi (3.24.1-2build1) ...\n",
            "Setting up module-init-tools (24-1ubuntu2) ...\n",
            "Setting up python3-software-properties (0.96.24.17) ...\n",
            "Setting up dbus (1.10.22-1ubuntu1) ...\n",
            "Setting up python-apt (1.4.0~beta3build2) ...\n",
            "Setting up python3-dbus (1.2.4-1build3) ...\n",
            "Setting up python-software-properties (0.96.24.17) ...\n",
            "Setting up software-properties-common (0.96.24.17) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Processing triggers for dbus (1.10.22-1ubuntu1) ...\n",
            "gpg: keybox '/tmp/tmpgk46dfk0/pubring.gpg' created\n",
            "gpg: /tmp/tmpgk46dfk0/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Selecting previously unselected package libfuse2:amd64.\n",
            "(Reading database ... 19804 files and directories currently installed.)\n",
            "Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package fuse.\n",
            "Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking fuse (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.6.21-0ubuntu2_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n",
            "Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up fuse (2.9.7-1ubuntu1) ...\n",
            "Setting up google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n",
            "Selecting previously unselected package libmecab2:amd64.\n",
            "(Reading database ... 19833 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libmecab2_0.996-3.1_amd64.deb ...\n",
            "Unpacking libmecab2:amd64 (0.996-3.1) ...\n",
            "Selecting previously unselected package libmecab-dev.\n",
            "Preparing to unpack .../1-libmecab-dev_0.996-3.1_amd64.deb ...\n",
            "Unpacking libmecab-dev (0.996-3.1) ...\n",
            "Selecting previously unselected package mecab-utils.\n",
            "Preparing to unpack .../2-mecab-utils_0.996-3.1_amd64.deb ...\n",
            "Unpacking mecab-utils (0.996-3.1) ...\n",
            "Selecting previously unselected package mecab-ipadic.\n",
            "Preparing to unpack .../3-mecab-ipadic_2.7.0-20070801+main-1_all.deb ...\n",
            "Unpacking mecab-ipadic (2.7.0-20070801+main-1) ...\n",
            "Selecting previously unselected package mecab.\n",
            "Preparing to unpack .../4-mecab_0.996-3.1_amd64.deb ...\n",
            "Unpacking mecab (0.996-3.1) ...\n",
            "Selecting previously unselected package mecab-ipadic-utf8.\n",
            "Preparing to unpack .../5-mecab-ipadic-utf8_2.7.0-20070801+main-1_all.deb ...\n",
            "Unpacking mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
            "Setting up libmecab2:amd64 (0.996-3.1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up mecab-utils (0.996-3.1) ...\n",
            "Setting up mecab-ipadic (2.7.0-20070801+main-1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up libmecab-dev (0.996-3.1) ...\n",
            "Setting up mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic-utf8 to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up mecab (0.996-3.1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "\u001b[33m  easy-tf-log 1.7 does not provide the extra 'tf'\u001b[0m\n",
            "Collecting pushbullet.py\n",
            "  Downloading https://files.pythonhosted.org/packages/72/91/78912bfb333f412be8f52bba4aa1c9b68d7f612e0fbc9fc5b88b4c894d26/pushbullet.py-0.11.0-py2.py3-none-any.whl\n",
            "Collecting python-magic (from pushbullet.py)\n",
            "  Downloading https://files.pythonhosted.org/packages/42/a1/76d30c79992e3750dac6790ce16f056f870d368ba142f83f75f694d93001/python_magic-0.4.15-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pushbullet.py) (2.18.4)\n",
            "Collecting websocket-client (from pushbullet.py)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/a1/72ef9aa26cfe1a75cee09fc1957e4723add9de098c15719416a1ee89386b/websocket_client-0.48.0-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K    100% |████████████████████████████████| 204kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=1.0.0->pushbullet.py) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=1.0.0->pushbullet.py) (2018.4.16)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=1.0.0->pushbullet.py) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=1.0.0->pushbullet.py) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client->pushbullet.py) (1.11.0)\n",
            "Installing collected packages: python-magic, websocket-client, pushbullet.py\n",
            "Successfully installed pushbullet.py-0.11.0 python-magic-0.4.15 websocket-client-0.48.0\n",
            "Collecting tweepy\n",
            "  Downloading https://files.pythonhosted.org/packages/05/f1/2e8c7b202dd04117a378ac0c55cc7dafa80280ebd7f692f1fa8f27fd6288/tweepy-3.6.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.0.0)\n",
            "Collecting PySocks>=1.5.7 (from tweepy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/12/6bf1d764f128636cef7408e8156b7235b150ea31650d0260969215bb8e7d/PySocks-1.6.8.tar.gz (283kB)\n",
            "\u001b[K    100% |████████████████████████████████| 286kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy) (2.18.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.11.0)\n",
            "Requirement already satisfied: oauthlib>=0.6.2 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (2018.4.16)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (2.6)\n",
            "Building wheels for collected packages: PySocks\n",
            "  Running setup.py bdist_wheel for PySocks ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/22/5c/b5/12e0dfdfa85bea67b23628b6425fae715c687e947a45ee3df9\n",
            "Successfully built PySocks\n",
            "Installing collected packages: PySocks, tweepy\n",
            "Successfully installed PySocks-1.6.8 tweepy-3.6.0\n",
            "Collecting mecab-python3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/e9/bbf5fc790a2bedd96fbaf47a84afa060bfb0b3e0217e5f64b32bd4bbad69/mecab-python3-0.7.tar.gz (41kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 2.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mecab-python3\n",
            "  Running setup.py bdist_wheel for mecab-python3 ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/4c/07/3a/5f22ccc9f381f3bc01fa023202061cd1e0e9af855292f005dd\n",
            "Successfully built mecab-python3\n",
            "Installing collected packages: mecab-python3\n",
            "Successfully installed mecab-python3-0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "90XCqkUfbnUZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "response = urllib.request.urlopen(\"https://raw.githubusercontent.com/yaroslavvb/memory_util/master/memory_util.py\")\n",
        "open(\"memory_util.py\", \"wb\").write(response.read())\n",
        "import memory_util"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WE9v1UerJMRo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import copy as copy\n",
        "import datetime\n",
        "import hashlib\n",
        "import json\n",
        "import os\n",
        "import os.path\n",
        "import filecmp\n",
        "import random\n",
        "import re\n",
        "import shutil\n",
        "import importlib\n",
        "\n",
        "\n",
        "import MeCab\n",
        "import easy_tf_log\n",
        "import matplotlib.pyplot as plt\n",
        "import random as random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tweepy\n",
        "import yaml\n",
        "from easy_tf_log import tflog\n",
        "from google.colab import auth\n",
        "from google.colab import files\n",
        "import importlib\n",
        "from pushbullet import Pushbullet\n",
        "from tensorflow.python.layers import core as layers_core\n",
        "from tensorflow.python.platform import gfile\n",
        "\n",
        "# Generate auth tokens for Colab\n",
        "auth.authenticate_user()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OoMe73Z51zNk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#kill_docker()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mM1uEwbYJPJK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "1a999f1c-eccf-467b-abad-f824444b92ee"
      },
      "cell_type": "code",
      "source": [
        "auth_google_drive()\n",
        "mount_google_drive()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VuC6wyLvVUlk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "fa8d7045-425a-4cc8-c311-ece226072776"
      },
      "cell_type": "code",
      "source": [
        "import drive.tensorflow_seq2seq_chatbot.lib.chatbot_model as sq"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "client1\n",
            "downloading config.yml...\n",
            "downloaded\n",
            "1.9.0-rc2\n",
            "module reloaded9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YPhaIY-BHV1Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reload_modules():\n",
        "  !fusermount -u drive\n",
        "  !google-drive-ocamlfuse -cc drive \n",
        "  importlib.reload(sq)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fNrRD9yOFXM6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "outputId": "9730cf9f-9c26-4824-f7ce-1e5ac08334ef"
      },
      "cell_type": "code",
      "source": [
        "if sq.mode == sq.Mode.Test:\n",
        "    sq.test_distributed_one(enable_attention=False)\n",
        "    sq.test_distributed_one(enable_attention=True)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==== test_distributed_pattern[ beam] ====\n",
            "WARNING:tensorflow:From /content/drive/tensorflow_seq2seq_chatbot/lib/chatbot_model.py:858: calling expand_dims (from tensorflow.python.ops.array_ops) with dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use the `axis` argument instead\n",
            "$$$ GPU ENABLED $$$\n",
            "$$$ GPU ENABLED $$$\n",
            "Created fresh model.\n",
            "INFO:tensorflow:Restoring parameters from model/test_distributed/ChatbotModel-100\n",
            "Inferred replies [6 3 7 4 1]\n",
            "logits [[-1.2900714  -5.8808107  -0.7343339   4.3347187  -4.059275    1.5587475\n",
            "   5.474302    0.17898077 -0.9195448 ]\n",
            " [-1.6834896  -6.892524   -3.1048987   5.6801476  -1.9099369   0.25509596\n",
            "   3.9646018   2.7475753  -0.9823034 ]\n",
            " [-2.2441032  -2.8392751  -3.6622686   2.0367935   2.1250422   1.1793109\n",
            "   0.4581913   4.0886135  -1.6223851 ]\n",
            " [-1.5222183   2.366472   -2.0782087  -2.616803    4.596033    1.687948\n",
            "  -2.8720033   2.9211202  -1.306099  ]\n",
            " [-0.6432748   6.966592    1.3353962  -6.4133725   4.187848    1.9390206\n",
            "  -4.048463    0.16939133 -0.9549587 ]]\n",
            "Inferred replies candidate0 [6 3 7 4 1]\n",
            "Inferred replies candidate1 [3 3 7 4 1]\n",
            "sample replies [[6 3 7 4 1]\n",
            " [6 3 7 4 1]\n",
            " [6 3 7 4 1]]\n",
            "Expected replies [6 3 7 4 1]\n",
            "==== test_distributed_pattern[attention beam] ====\n",
            "$$$ GPU ENABLED $$$\n",
            "$$$ GPU ENABLED $$$\n",
            "Created fresh model.\n",
            "INFO:tensorflow:Restoring parameters from model/test_distributed/ChatbotModel-100\n",
            "Inferred replies [4 7 7 7 1]\n",
            "logits [[ -0.4902337  -10.506988    -7.5677204    6.5741014   12.075029\n",
            "    7.386207    -0.99986374   2.8270361  -10.137192  ]\n",
            " [ -0.39743385   2.5827656  -10.759244    -2.1816034    5.59574\n",
            "   -3.0964594   -2.6108172   11.454566    -2.8054812 ]\n",
            " [ -0.6976772    3.2308934   -9.495427    -2.5667396    4.275293\n",
            "   -3.032791    -2.4232175   10.503424    -2.118344  ]\n",
            " [ -1.4720391    4.5108733   -6.3184705   -3.121827     1.3990569\n",
            "   -2.1030297   -2.1755912    7.9987216   -1.170017  ]\n",
            " [ -2.4959373    7.477863    -1.0859077   -4.5242434   -4.568854\n",
            "   -3.0127516   -0.64497817   3.9519506    2.528915  ]]\n",
            "Inferred replies candidate0 [4 7 7 7 1]\n",
            "Inferred replies candidate1 [4 7 7 1 1]\n",
            "sample replies [[4 7 7 7 1]\n",
            " [4 7 7 7 1]\n",
            " [4 7 7 7 1]]\n",
            "Expected replies [4 7 7 7 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JrvS_DURF5Pq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5494
        },
        "outputId": "72d3eb3c-268c-473f-dafa-014d57012543"
      },
      "cell_type": "code",
      "source": [
        "tweet_small_hparams = copy.deepcopy(sq.base_hparams).override_from_dict(\n",
        "    {\n",
        "        'batch_size': 6,  # of tweets should be dividable by batch_size\n",
        "        'encoder_length': 8,\n",
        "        'decoder_length': 8,\n",
        "        'num_units': 256,\n",
        "        'num_layers': 2,\n",
        "        'vocab_size': 34,\n",
        "        'embedding_size': 40,\n",
        "        'beam_width': 2,  # for faster iteration, this should be 10\n",
        "        'num_train_steps': 200,\n",
        "        'model_path': sq.ModelDirectory.tweet_small.value,\n",
        "        'learning_rate': 0.05,\n",
        "        'use_attention': True,\n",
        "    })\n",
        "\n",
        "tweet_small_swapped_hparams = copy.deepcopy(\n",
        "    tweet_small_hparams).override_from_dict(\n",
        "    {'model_path': sq.ModelDirectory.tweet_small_swapped.value})\n",
        "\n",
        "if sq.mode == sq.Mode.Test:\n",
        "    tweets_path = \"tweets_small.txt\"\n",
        "    sq.TrainDataGenerator(tweets_path, tweet_small_hparams).remove_generated()\n",
        "    trainer = sq.Trainer()\n",
        "    trainer.train_seq2seq(tweet_small_hparams, tweets_path,\n",
        "                          [\"おはようございます。寒いですね。\", \"さて帰ろう。明日は早い。\", \"今回もよろしくです。\"])\n",
        "    sq.test_tweets_small_swapped(tweet_small_swapped_hparams)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== Train Seq2Seq tweets_small.txt ====\n",
            "{'machine': 'client1', 'batch_size': 6, 'num_units': 256, 'num_layers': 2, 'vocab_size': 34, 'embedding_size': 40, 'learning_rate': 0.05, 'learning_rate_decay': 0.99, 'use_attention': True, 'encoder_length': 8, 'decoder_length': 8, 'max_gradient_norm': 5.0, 'beam_width': 2, 'num_train_steps': 200, 'model_path': 'model/tweet_small'}\n",
            "downloading tweets_small.txt...\n",
            "downloaded\n",
            "generating enc and dec files...\n",
            "generating vocab file...\n",
            "loading vocab...\n",
            "generating id files...\n",
            "generating padded input file...\n",
            "generating dec eos/sos files...\n",
            "done\n",
            "Downloading model files...\n",
            "done\n",
            "$$$ GPU ENABLED $$$\n",
            "$$$ GPU ENABLED $$$\n",
            "$$$ GPU ENABLED $$$\n",
            "Created fresh model.\n",
            "....................INFO:tensorflow:Restoring parameters from model/tweet_small/ChatbotModel-21\n",
            "==== 21 ====\n",
            "おはようございます。寒いですね。\n",
            "    [0]ございございますます \n",
            "    [1]ございございます  \n",
            "    [2]ございございますます \n",
            "さて帰ろう。明日は早い。\n",
            "    [0]おございますます \n",
            "    [1]ございございますます \n",
            "    [2]おございますます \n",
            "今回もよろしくです。\n",
            "    [0]ございますます \n",
            "    [1]ございますます \n",
            "    [2]おはようますます \n",
            "average reply len=9.3\n",
            "validation loss=16.4\n",
            "...................INFO:tensorflow:Restoring parameters from model/tweet_small/ChatbotModel-41\n",
            "==== 41 ====\n",
            "おはようございます。寒いですね。\n",
            "    [0]おはようございさます \n",
            "    [1]おはようございさます \n",
            "    [2]おございさます \n",
            "さて帰ろう。明日は早い。\n",
            "    [0]おつかれさます \n",
            "    [1]おつかれさます \n",
            "    [2]おございさます \n",
            "今回もよろしくです。\n",
            "    [0]おつかれますます \n",
            "    [1]おつかれますます \n",
            "    [2]おはようございますます \n",
            "average reply len=9.3\n",
            "validation loss=13.7\n",
            "...................INFO:tensorflow:Restoring parameters from model/tweet_small/ChatbotModel-61\n",
            "==== 61 ====\n",
            "おはようございます。寒いですね。\n",
            "    [0]おはようございさます \n",
            "    [1]おはようございさます \n",
            "    [2]おございさます \n",
            "さて帰ろう。明日は早い。\n",
            "    [0]おつかれさます \n",
            "    [1]おつかれさます \n",
            "    [2]おございさます \n",
            "今回もよろしくです。\n",
            "    [0]おはようこそますます \n",
            "    [1]おはようこそますます \n",
            "    [2]おこそますます \n",
            "average reply len=10.0\n",
            "validation loss=12.1\n",
            "...................INFO:tensorflow:Restoring parameters from model/tweet_small/ChatbotModel-81\n",
            "==== 81 ====\n",
            "おはようございます。寒いですね。\n",
            "    [0]おはようございますます \n",
            "    [1]おはようございますます \n",
            "    [2]おはようございさます \n",
            "さて帰ろう。明日は早い。\n",
            "    [0]おつかれさます \n",
            "    [1]おつかれさます \n",
            "    [2]おはようつかれさます \n",
            "今回もよろしくです。\n",
            "    [0]こちらこそよろしくます \n",
            "    [1]こちらこそよろしくます \n",
            "    [2]こちらこそますます \n",
            "average reply len=10.7\n",
            "validation loss=10.0\n",
            "...................INFO:tensorflow:Restoring parameters from model/tweet_small/ChatbotModel-101\n",
            "==== 101 ====\n",
            "おはようございます。寒いですね。\n",
            "    [0]おはようつかれさ！ \n",
            "    [1]おはようつかれさ！ \n",
            "    [2]おはようございさ！ \n",
            "さて帰ろう。明日は早い。\n",
            "    [0]おつかれさまー \n",
            "    [1]おつかれさま  \n",
            "    [2]おつかれさまー \n",
            "今回もよろしくです。\n",
            "    [0]こちらこそよろしくお願いし \n",
            "    [1]こちらこそよろしくお願い  \n",
            "    [2]こちらこそよろしくお願いし \n",
            "average reply len=10.7\n",
            "validation loss=7.3\n",
            "...................INFO:tensorflow:Restoring parameters from model/tweet_small/ChatbotModel-121\n",
            "==== 121 ====\n",
            "おはようございます。寒いですね。\n",
            "    [0]おはようございます！！。。。\n",
            "    [1]おはようございます！！。。。\n",
            "    [2]おはようございます！！。。 \n",
            "さて帰ろう。明日は早い。\n",
            "    [0]おつかれさまー。。気\n",
            "    [1]おつかれさまー。。気\n",
            "    [2]おつかれさまー。気気\n",
            "今回もよろしくです。\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    [0]こちらこそよろしくお願いしします。\n",
            "    [1]こちらこそよろしくお願いしします。\n",
            "    [2]こちらこそよろしくお願いお願いします。\n",
            "average reply len=13.7\n",
            "validation loss=5.4\n",
            "...................INFO:tensorflow:Restoring parameters from model/tweet_small/ChatbotModel-141\n",
            "==== 141 ====\n",
            "おはようございます。寒いですね。\n",
            "    [0]おはようございます！！。 \n",
            "    [1]おはようございます！   \n",
            "    [2]おはようございます！！。 \n",
            "さて帰ろう。明日は早い。\n",
            "    [0]おつかれさまー。気気\n",
            "    [1]おつかれさまー。気気\n",
            "    [2]おつかれさまーー気気\n",
            "今回もよろしくです。\n",
            "    [0]こちらこそよろしくお願いしします。\n",
            "    [1]こちらこそよろしくお願いしします。\n",
            "    [2]こちらこそよろしくお願いしますます。\n",
            "average reply len=13.3\n",
            "validation loss=4.2\n",
            "...................INFO:tensorflow:Restoring parameters from model/tweet_small/ChatbotModel-161\n",
            "==== 161 ====\n",
            "おはようございます。寒いですね。\n",
            "    [0]おはようございます！！。 \n",
            "    [1]おはようございます！   \n",
            "    [2]おはようございます！！。 \n",
            "さて帰ろう。明日は早い。\n",
            "    [0]おつかれさまー。気気\n",
            "    [1]おつかれさまー。気気\n",
            "    [2]おつかれさまー。。気\n",
            "今回もよろしくです。\n",
            "    [0]こちらこそよろしくお願いします。。\n",
            "    [1]こちらこそよろしくお願いします。。\n",
            "    [2]こちらこそよろしくお願いしますます。\n",
            "average reply len=13.3\n",
            "validation loss=3.5\n",
            "...................INFO:tensorflow:Restoring parameters from model/tweet_small/ChatbotModel-181\n",
            "==== 181 ====\n",
            "おはようございます。寒いですね。\n",
            "    [0]おはようございます！ \n",
            "    [1]おはようございます！  \n",
            "    [2]おはようございます！！ \n",
            "さて帰ろう。明日は早い。\n",
            "    [0]おつかれさまー。気気\n",
            "    [1]おつかれさまー。気気\n",
            "    [2]おつかれさまー。。気\n",
            "今回もよろしくです。\n",
            "    [0]こちらこそよろしくお願いしし。。\n",
            "    [1]こちらこそよろしくお願いしし。。\n",
            "    [2]こちらこそよろしくお願いします。。\n",
            "average reply len=12.3\n",
            "validation loss=2.9\n",
            "...................===== Train Seq2Seq tweets_small_swapped.txt ====\n",
            "{'machine': 'client1', 'batch_size': 6, 'num_units': 256, 'num_layers': 2, 'vocab_size': 34, 'embedding_size': 40, 'learning_rate': 0.05, 'learning_rate_decay': 0.99, 'use_attention': True, 'encoder_length': 8, 'decoder_length': 8, 'max_gradient_norm': 5.0, 'beam_width': 2, 'num_train_steps': 200, 'model_path': 'model/tweet_small_swapped'}\n",
            "generating enc and dec files...\n",
            "generating vocab file...\n",
            "loading vocab...\n",
            "generating id files...\n",
            "generating padded input file...\n",
            "generating dec eos/sos files...\n",
            "done\n",
            "Downloading model files...\n",
            "done\n",
            "$$$ GPU ENABLED $$$\n",
            "$$$ GPU ENABLED $$$\n",
            "$$$ GPU ENABLED $$$\n",
            "Created fresh model.\n",
            "....................INFO:tensorflow:Restoring parameters from model/tweet_small_swapped/ChatbotModel-21\n",
            "==== 21 ====\n",
            "@higepon おはようございます！\n",
            "    [0]。。。。 \n",
            "    [1]。。。。 \n",
            "    [2]さて。。。 \n",
            "おつかれさまー。気をつけて。\n",
            "    [0]さて。。。。 \n",
            "    [1]さて。。。  \n",
            "    [2]さて。。。。 \n",
            "こちらこそよろしくお願いします。\n",
            "    [0]さて。。。。 \n",
            "    [1]さて。。。  \n",
            "    [2]さて。。。。 \n",
            "average reply len=6.3\n",
            "validation loss=17.1\n",
            "...................INFO:tensorflow:Restoring parameters from model/tweet_small_swapped/ChatbotModel-41\n",
            "==== 41 ====\n",
            "@higepon おはようございます！\n",
            "    [0]さてう。です \n",
            "    [1]さてう。です \n",
            "    [2]さてよろしく。です \n",
            "おつかれさまー。気をつけて。\n",
            "    [0]さて帰ろう。。 \n",
            "    [1]さて帰ろう。。 \n",
            "    [2]さて帰ろ。。。 \n",
            "こちらこそよろしくお願いします。\n",
            "    [0]さて帰ろ。。 \n",
            "    [1]さて帰ろ。。 \n",
            "    [2]さても。。 \n",
            "average reply len=7.3\n",
            "validation loss=13.4\n",
            "...................INFO:tensorflow:Restoring parameters from model/tweet_small_swapped/ChatbotModel-61\n",
            "==== 61 ====\n",
            "@higepon おはようございます！\n",
            "    [0]今回ござい。です \n",
            "    [1]今回ござい。です  \n",
            "    [2]今回ござい。ですです \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "おつかれさまー。気をつけて。\n",
            "    [0]さて帰ろう。明日 \n",
            "    [1]さて帰ろう。明日 \n",
            "    [2]さて帰ろう。です \n",
            "こちらこそよろしくお願いします。\n",
            "    [0]さて帰ろよろしく。です \n",
            "    [1]さて帰ろよろしく。です \n",
            "    [2]さて帰ろう。です \n",
            "average reply len=10.0\n",
            "validation loss=11.4\n",
            "...................INFO:tensorflow:Restoring parameters from model/tweet_small_swapped/ChatbotModel-81\n",
            "==== 81 ====\n",
            "@higepon おはようございます！\n",
            "    [0]おはようございますですです \n",
            "    [1]おはようございますですです \n",
            "    [2]今回ございますですです \n",
            "おつかれさまー。気をつけて。\n",
            "    [0]さて帰ろう明日明日 \n",
            "    [1]さて帰ろう明日明日 \n",
            "    [2]さて帰ろよろしく明日明日 \n",
            "こちらこそよろしくお願いします。\n",
            "    [0]さて帰ろよろしく。です \n",
            "    [1]さて帰ろよろしく。です \n",
            "    [2]さてもよろしく。です \n",
            "average reply len=12.0\n",
            "validation loss=9.6\n",
            "...................INFO:tensorflow:Restoring parameters from model/tweet_small_swapped/ChatbotModel-101\n",
            "==== 101 ====\n",
            "@higepon おはようございます！\n",
            "    [0]おはようございますですです \n",
            "    [1]おはようございますですです \n",
            "    [2]おはようございますです寒い \n",
            "おつかれさまー。気をつけて。\n",
            "    [0]さて帰ろう明日明日 \n",
            "    [1]さて帰ろう明日明日 \n",
            "    [2]さて帰ろう。明日 \n",
            "こちらこそよろしくお願いします。\n",
            "    [0]今回もよろしく。です \n",
            "    [1]今回もよろしく。です \n",
            "    [2]今回帰ろよろしく。です \n",
            "average reply len=11.7\n",
            "validation loss=8.0\n",
            "...................INFO:tensorflow:Restoring parameters from model/tweet_small_swapped/ChatbotModel-121\n",
            "==== 121 ====\n",
            "@higepon おはようございます！\n",
            "    [0]おはようございます。寒い寒いねね\n",
            "    [1]おはようございます。寒い寒いねね\n",
            "    [2]おはようございます。寒いですねね\n",
            "おつかれさまー。気をつけて。\n",
            "    [0]さて帰ろう。。は \n",
            "    [1]さて帰ろう。。は \n",
            "    [2]さて帰ろよろしく。。は \n",
            "こちらこそよろしくお願いします。\n",
            "    [0]今回もよろしく。。です \n",
            "    [1]今回もよろしく。。  \n",
            "    [2]今回もよろしく。。です \n",
            "average reply len=12.3\n",
            "validation loss=6.7\n",
            "...................INFO:tensorflow:Restoring parameters from model/tweet_small_swapped/ChatbotModel-141\n",
            "==== 141 ====\n",
            "@higepon おはようございます！\n",
            "    [0]おはようございます。寒いです \n",
            "    [1]おはようございます。寒いです \n",
            "    [2]おはようございます。寒い寒い \n",
            "おつかれさまー。気をつけて。\n",
            "    [0]さて帰ろう。。 \n",
            "    [1]さて帰ろう。。 \n",
            "    [2]さて帰ろよろしく。。 \n",
            "こちらこそよろしくお願いします。\n",
            "    [0]今回もよろしく。。 \n",
            "    [1]今回もよろしく。。 \n",
            "    [2]今回もよろしく。です \n",
            "average reply len=11.0\n",
            "validation loss=5.5\n",
            "...................INFO:tensorflow:Restoring parameters from model/tweet_small_swapped/ChatbotModel-161\n",
            "==== 161 ====\n",
            "@higepon おはようございます！\n",
            "    [0]おはようございますですですね \n",
            "    [1]おはようございますですですね \n",
            "    [2]おはようございますです寒いね \n",
            "おつかれさまー。気をつけて。\n",
            "    [0]さて帰ろう明日明日は \n",
            "    [1]さて帰ろう明日明日は \n",
            "    [2]さて帰ろう。明日は \n",
            "こちらこそよろしくお願いします。\n",
            "    [0]今回もよろしくですです \n",
            "    [1]今回もよろしくですです \n",
            "    [2]今回もよろしく。です \n",
            "average reply len=12.7\n",
            "validation loss=4.7\n",
            "...................INFO:tensorflow:Restoring parameters from model/tweet_small_swapped/ChatbotModel-181\n",
            "==== 181 ====\n",
            "@higepon おはようございます！\n",
            "    [0]おはようございますですですね \n",
            "    [1]おはようございますですですね \n",
            "    [2]おはようございますですですです \n",
            "おつかれさまー。気をつけて。\n",
            "    [0]さて帰ろう。明日は \n",
            "    [1]さて帰ろう。明日は \n",
            "    [2]さて帰ろう明日明日は \n",
            "こちらこそよろしくお願いします。\n",
            "    [0]今回もよろしくですです \n",
            "    [1]今回もよろしくですです \n",
            "    [2]今回もよろしくです。 \n",
            "average reply len=12.3\n",
            "validation loss=4.0\n",
            "..................."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tzh2rhEPguJ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tweet_large_hparams = copy.deepcopy(sq.base_hparams).override_from_dict(\n",
        "    {\n",
        "        # In typical seq2seq chatbot\n",
        "        # num_layers=3, learning_rate=0.5, batch_size=64, vocab=20000-100000, learning_rate decay is 0.99, which is taken care as default parameter in AdamOptimizer.\n",
        "        'batch_size': 64,  # of tweets should be dividable by batch_size\n",
        "        'encoder_length': 28,\n",
        "        'decoder_length': 28,\n",
        "        'num_units': 1024,\n",
        "        'num_layers': 3,\n",
        "        'vocab_size': 60000,\n",
        "    # conversations.txt actually has about 70K uniq words.\n",
        "        'embedding_size': 1024,\n",
        "        'beam_width': 2,  # for faster iteration, this should be 10\n",
        "        'num_train_steps': 1000000,\n",
        "        'model_path': sq.ModelDirectory.tweet_large.value,\n",
        "        'learning_rate': 0.5,\n",
        "    # For vocab_size 50000, num_layers 3, num_units 1024, tweet_large, starting learning_rate 0.05 works well, change it t0 0.01 at perplexity 800, changed it to 0.005 at 200.\n",
        "        'learning_rate_decay': 0.99,\n",
        "        'use_attention': True,\n",
        "        # testing new restore learning rate and no USERNAME TOKEN\n",
        "    })\n",
        "\n",
        "tweet_large_swapped_hparams = copy.deepcopy(\n",
        "    tweet_large_hparams).override_from_dict(\n",
        "    {\n",
        "        'model_path': sq.ModelDirectory.tweet_large_swapped.value\n",
        "    })\n",
        "\n",
        "#Shell.save_model_in_drive(tweet_large_hparams.model_path)\n",
        "\n",
        "if sq.mode == sq.Mode.TrainSeq2Seq:\n",
        "    print(\"train seq2seq\")\n",
        "    sq.test_tweets_large(tweet_large_hparams)\n",
        "elif sq.mode == sq.Mode.TrainSeq2SeqSwapped:\n",
        "    print(\"train seq2seq swapped\")\n",
        "    sq.test_tweets_large_swapped(tweet_large_swapped_hparams)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "swhAySRidGr-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "df29ffd3-17f9-48b3-b251-de9768a5f27f"
      },
      "cell_type": "code",
      "source": [
        "!ls -Sl model/conversations_large*"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model/conversations_large:\r\n",
            "total 0\r\n",
            "\r\n",
            "model/conversations_large_backward:\r\n",
            "total 0\r\n",
            "\r\n",
            "model/conversations_large_rl:\r\n",
            "total 0\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uWLrKkcC3TXM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "outputId": "50eb1bd7-046f-4bc8-8c47-313f2eebf63b"
      },
      "cell_type": "code",
      "source": [
        "  \n",
        "reload_modules()\n",
        "\n",
        "conversations_large_hparams = copy.deepcopy(sq.base_hparams).override_from_dict(\n",
        "    {\n",
        "        # In typical seq2seq chatbot\n",
        "        # num_layers=3, learning_rate=0.5, batch_size=64, vocab=20000-100000, learning_rate decay is 0.99, which is taken care as default parameter in AdamOptimizer.\n",
        "        'batch_size': 64,  # of tweets should be dividable by batch_size\n",
        "        'encoder_length': 28,\n",
        "        'decoder_length': 28,\n",
        "        'num_units': 1024,\n",
        "        'num_layers': 3,\n",
        "        'vocab_size': 60000,\n",
        "    # conversations.txt actually has about 70K uniq words.\n",
        "        'embedding_size': 1024,\n",
        "        'beam_width': 2,  # for faster iteration, this should be 10\n",
        "        'num_train_steps': 0,\n",
        "        'model_path': sq.ModelDirectory.conversations_large.value,\n",
        "        'learning_rate': 0.5,\n",
        "    # For vocab_size 50000, num_layers 3, num_units 1024, tweet_large, starting learning_rate 0.05 works well, change it t0 0.01 at perplexity 800, changed it to 0.005 at 200.\n",
        "        'learning_rate_decay': 0.99,\n",
        "        'use_attention': True,\n",
        "\n",
        "    })\n",
        "\n",
        "conversations_large_rl_hparams = copy.deepcopy(\n",
        "    conversations_large_hparams).override_from_dict(\n",
        "    {\n",
        "        'model_path': sq.ModelDirectory.conversations_large_rl.value,\n",
        "        'num_train_steps': 8000,\n",
        "        'beam_width': 3,\n",
        "    })\n",
        "\n",
        "\n",
        "conversations_large_backward_hparams = copy.deepcopy(\n",
        "    conversations_large_hparams).override_from_dict(\n",
        "    {\n",
        "        'model_path': sq.ModelDirectory.conversations_large_backward.value,\n",
        "        'num_train_steps': 0,        \n",
        "    })\n",
        "\n",
        "\n",
        "conversations_txt = \"conversations_large.txt\"\n",
        "sq.Shell.download_file_if_necessary(conversations_txt)\n",
        "sq.ConversationTrainDataGenerator().generate(conversations_txt)\n",
        "\n",
        "with memory_util.capture_stderr() as stderr:\n",
        "    try:\n",
        "        trainer =sq.Trainer()\n",
        "        valid_tweets = [\"さて福岡行ってきます！\", \"誰か飲みに行こう\", \"熱でてるけど、でもなんか食べなきゃーと思ってアイス買おうとしたの\",\n",
        "              \"今日のドラマ面白そう！\", \"お腹すいたー\", \"おやすみ～\", \"おはようございます。寒いですね。\",\n",
        "              \"さて帰ろう。明日は早い。\", \"今回もよろしくです。\", \"ばいとおわ！\"]\n",
        "        trainer.train_seq2seq(conversations_large_hparams,\n",
        "                              \"conversations_large_seq2seq.txt\",\n",
        "                              valid_tweets, should_clean_saved_model=False)\n",
        "        trainer.train_seq2seq_swapped(conversations_large_backward_hparams,\n",
        "                                      \"conversations_large_seq2seq.txt\",\n",
        "                                      [\"この難にでも応用可能なひどいやつ\", \"おはようございます。明日はよろしくおねがいします。\"], vocab_path=\"conversations_large_seq2seq_vocab.txt\", should_clean_saved_model=False)\n",
        "\n",
        "        sq.Shell.copy_saved_model(conversations_large_hparams, conversations_large_rl_hparams)\n",
        "        sq.Trainer().train_rl(conversations_large_rl_hparams,\n",
        "                                conversations_large_hparams,\n",
        "                                conversations_large_backward_hparams,\n",
        "                                \"conversations_large_seq2seq.txt\",\n",
        "\n",
        "                                \"conversations_large_rl.txt\",\n",
        "                                valid_tweets)\n",
        "    except Exception as e:\n",
        "        print(stderr.getvalue())\n",
        "        raise (e)\n",
        "\n",
        "!ls - lSh\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clearing cache...done\r\n",
            "client1\n",
            "1.9.0-rc2\n",
            "module reloaded9\n",
            "downloading conversations_large.txt...\n",
            "downloaded\n",
            "===== Train Seq2Seq conversations_large_seq2seq.txt ====\n",
            "{'machine': 'client1', 'batch_size': 64, 'num_units': 1024, 'num_layers': 3, 'vocab_size': 60000, 'embedding_size': 1024, 'learning_rate': 0.5, 'learning_rate_decay': 0.99, 'use_attention': True, 'encoder_length': 28, 'decoder_length': 28, 'max_gradient_norm': 5.0, 'beam_width': 2, 'num_train_steps': 0, 'model_path': 'model/conversations_large'}\n",
            "generating enc and dec files...\n",
            "generating vocab file...\n",
            "vocab_len= 391565\n",
            "loading vocab...\n",
            "generating id files...\n",
            "generating padded input file...\n",
            "generating dec eos/sos files...\n",
            "done\n",
            "Downloading model files...\n",
            "Copying  drive/seq2seq_data/model/conversations_large/events.out.tfevents.1530186369.67a0b8527e19\n",
            "Copying  drive/seq2seq_data/model/conversations_large/events.out.tfevents.1530186319.67a0b8527e19\n",
            "Copying  drive/seq2seq_data/model/conversations_large/events.out.tfevents.1530109115.1cfeca23cb88\n",
            "Copying  drive/seq2seq_data/model/conversations_large/checkpoint\n",
            "Copying  drive/seq2seq_data/model/conversations_large/ChatbotModel-27584.meta\n",
            "Copying  drive/seq2seq_data/model/conversations_large/ChatbotModel-27584.index\n",
            "Copying  drive/seq2seq_data/model/conversations_large/ChatbotModel-27584.data-00000-of-00001\n",
            "Copying  drive/seq2seq_data/model/conversations_large/events.out.tfevents.1529845842.4a4f7239805d\n",
            "Copying  drive/seq2seq_data/model/conversations_large/events.out.tfevents.1530177405.67a0b8527e19\n",
            "Copying  drive/seq2seq_data/model/conversations_large/events.out.tfevents.1529845774.4a4f7239805d\n",
            "Copying  drive/seq2seq_data/model/conversations_large/events.out.tfevents.1530109067.1cfeca23cb88\n",
            "Copying  drive/seq2seq_data/model/conversations_large/events.out.tfevents.1530177455.67a0b8527e19\n",
            "done\n",
            "$$$ GPU ENABLED $$$\n",
            "$$$ GPU ENABLED $$$\n",
            "$$$ GPU ENABLED $$$\n",
            "INFO:tensorflow:Restoring parameters from model/conversations_large/ChatbotModel-27584\n",
            "===== Train Seq2Seq conversations_large_seq2seq_swapped.txt ====\n",
            "{'machine': 'client1', 'batch_size': 64, 'num_units': 1024, 'num_layers': 3, 'vocab_size': 60000, 'embedding_size': 1024, 'learning_rate': 0.5, 'learning_rate_decay': 0.99, 'use_attention': True, 'encoder_length': 28, 'decoder_length': 28, 'max_gradient_norm': 5.0, 'beam_width': 2, 'num_train_steps': 0, 'model_path': 'model/conversations_large_backward'}\n",
            "generating enc and dec files...\n",
            "generating vocab file...\n",
            "loading vocab...\n",
            "generating id files...\n",
            "generating padded input file...\n",
            "generating dec eos/sos files...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T_q-Ns9hiHMB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "b5eff6d5-ba89-4826-8f32-cea09e2d4858"
      },
      "cell_type": "code",
      "source": [
        "# N.B: This would fail if we try to download logs in the previous cell.\n",
        "# My guess is tflog is somehow locking the log file when running the cell.\n",
        "sq.Shell.download_logs(conversations_large_rl_hparams.model_path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-548b74e6d760>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mShell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconversations_large_rl_hparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'sq' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "CErAqa_dxzQy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}